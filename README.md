BTC-Transformer Â· Minuteâ€‘Level Bitcoin Trend Forecast with Transformer\n\n> TL;DR: This repository offers a full endâ€‘toâ€‘end workflow â€” from raw Binance Kâ€‘line CSV â†’ feature engineering â†’ automatic labelling â†’ Transformer training & hyperâ€‘parameter tuning â†’ inference & visualisation â€” with CPU/GPU acceleration at every stage.\n\n---\n\n## âœ¨ Highlights\n\n* Time2Vector temporal embedding â€” SineActivation first applies a linear map and then concatenates multiâ€‘frequency sine components to expand the original features to hidden_dim, effectively injecting periodic patterns. îˆ€fileciteîˆ‚turn0file1îˆ\n* Pure encoder architecture â€” only nn.TransformerEncoder is used; no decoder is required for training or inference, which simplifies parallelism and deployment. îˆ€fileciteîˆ‚turn0file1îˆ\n* Optuna hyperâ€‘parameter search â€” bitcoin_price_prediction_optuna.py explores a 20+â€‘dimensional space with pruning, dynamically balancing CPU/GPU workloads. îˆ€fileciteîˆ‚turn0file5îˆ\n* Multiâ€‘process feature engineering â€” add_finta_feature_parallel utilises 100+ processes to compute Finta technical indicators, fully saturating the CPU. îˆ€fileciteîˆ‚turn0file7îˆ\n* Selfâ€‘supervised trend labels â€” detect_trend(_optimized) generates the binary trend_returns label based on drawâ€‘down thresholds, eliminating manual labelling. îˆ€fileciteîˆ‚turn0file3îˆ\n\n---\n\n## ğŸ“‚ Repository Layout\n\ntext\nâ”œâ”€â”€ bitcoin_price_prediction.py          # Baseline training script (singleâ€‘node)\nâ”œâ”€â”€ bitcoin_price_prediction_optuna.py   # Hyperâ€‘parameter search + retrain + visualisation\nâ”œâ”€â”€ model.py                             # BTC_Transformer & Time2Vector\nâ”œâ”€â”€ evaluation.py                        # Validation / test loops\nâ”œâ”€â”€ data_process.py                      # Data preprocessing & batch sampling\nâ”œâ”€â”€ set_target.py                        # Generate trend_returns label\nâ”œâ”€â”€ reform.py                            # Notebook â†’ .py converter\nâ””â”€â”€ cuda.py                              # GPU environment check\n\n\n---\n\n## âš™ï¸ Environment\n\n| Component | Version |\n|-----------|---------|\n| Python | â‰¥ 3.10 |\n| PyTorch | â‰¥ 2.2, CUDAÂ 11.8 |\n| pandas / numpy / matplotlib / seaborn | latest |\n| finta | technicalâ€‘indicator library |\n| optuna | â‰¥Â 3.6 |\n| numba / scikitâ€‘learn | latest |\n\nbash\nconda create -n btc-transformer python=3.10 pytorch cudatoolkit=11.8 -c pytorch -c conda-forge\nconda activate btc-transformer\npip install -r requirements.txt\n\n\nExample requirements.txt:\n\ntext\npandas numpy matplotlib seaborn scikit-learn finta optuna numba torchsummary tqdm\n\n\n---\n\n## ğŸ“‘ Data Preparation\n\n1. Download BTCUSDT-1m / BTCUSDT-3m Kâ€‘line CSV from Binance (official) or Kaggle.\n2. Place files under input/btcusdt/ with names like BTCUSDT-1m-2024-12.csv.\n3. Running any training script will automatically:\n   * compute 25+ Finta indicators;\n   * call detect_trend / detect_trend_optimized to create trend_returns;\n   * split train / validation / test in an 8â€¯:â€¯1â€¯:â€¯1 ratio.\n\n---\n\n## ğŸš€ Quick Start\n\n### 1. Baseline training\n\nbash\npython bitcoin_price_prediction.py --epochs 50 --device cuda:0\n\n\nThe script prints training/validation loss curves and saves convergence plots.\n\n### 2. Hyperâ€‘parameter search\n\nbash\npython bitcoin_price_prediction_optuna.py --trials 200 --n_jobs 32\n\n\n* 18 dimensions are searched, including Transformer depth, hidden size, learning rate, etc.;\n* CPU/GPU resources are scheduled automatically for maximum throughput;\n* The best model is stored as best_model_final.pt, with hyperâ€‘parameters in best_params.json.\n\n---\n\n## ğŸ“ Evaluation & Inference\n\npython\nfrom model import BTC_Transformer\nfrom bitcoin_price_prediction_optuna import define_model\nimport torch, json\n\nbest_params = json.load(open("best_params.json"))\nmodel, _ = define_model(best_params, torch.device("cuda:0"))\nmodel.load_state_dict(torch.load("best_model_final.pt"))\nmodel.eval()\n\n\nSee estimate_BTC for a sample prediction pipeline that returns deâ€‘normalised groundâ€‘truth and forecast series ready for backâ€‘testing. îˆ€fileciteîˆ‚turn0file4îˆ\n\n---\n\n## ğŸ“Š Example Results (3â€‘Minute, 2022â€‘01 â†’ 09)\n\n| Metric | Baseline | Optuna Best |\n|--------|----------|-------------|\n| Test Loss (CE) | 0.51 | 0.34 |\n| â†‘ Directional Accuracy | 61â€¯% | 69â€¯% |\n\n> Hardware: single RTXÂ 4090; results for reference only.\n\n---\n\n## ğŸ› ï¸ Customisation & Extensions\n\n* Switch to another coin â€” simply replace the CSV; indicators and labelling remain unchanged.\n* Regression task â€” disable the classifier, enable the generator, and swap the loss to nn.L1Loss().\n* Multiâ€‘scale windows â€” sample bptt_src / tgt inside the Optuna objective for stronger generalisation.\n* Integrate WandB â€” a oneâ€‘liner to track experiments (see TODO).\n\n---\n\n## ğŸ“ TODO\n\n- [ ] Integrate Informer or PatchTST to reduce latency\n- [ ] Use GPUâ€‘Numba/CuPy to accelerate label generation\n- [ ] WandB experiment tracking & featureâ€‘importance analysis\n- [ ] Lightweight backâ€‘test engine for profit evaluation\n\n---\n\n## ğŸ“œ License\n\nReleased under the MIT License; see the LICENSE file for details.



Hope this was helpful and please let us know if you have any comments on this work:

https://github.com/yuvalaya

https://github.com/baruch1192
